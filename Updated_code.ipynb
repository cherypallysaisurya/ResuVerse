{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cherypallysaisurya/ResuVerse/blob/main/Updated_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QB9Ly_DxYaRU",
        "outputId": "a22a59af-23d8-419e-a254-bc537dbe3fc2"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n",
            "WARNING:pdfminer.pdfpage:CropBox missing from /Page, defaulting to MediaBox\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üìÑ Job Description Summary:\n",
            " The Kern Behavioral Health and Recovery Services (KernBHRS) administration office is located in Bakersfield, the county sear, in the southern region of the San Joaquin Valley. The Department‚Äôs goal is to ensure the citizens of Kern County who are afflicted with mental and behavioral health disorders are provided with services and resources necessary for their treatment and recovery. The County is divided into eleven (11) Geographic Service Areas for serving individuals needing mental health care.\n",
            "4 clinics, Kern County Jail or Crisis Stabilization Unit located in the greater Bakersfield area. The Department expects to spend approximately $2,100,000 per fiscal year for these services among all providers. Three Agreements will be negotiated between KernBHRS and the prospective service provider.\n",
            "The parties agree that the venue of any action relating to this agreement shall be in the County of Kern. It is understood that Contractor, in Contractor‚Äôs performance of any and all duties under this agreement, has no authority to bind County to any agreements or undertakings.\n",
            "No inducements, representations, or promises have been made, other than those recited in this agreement. No oral promise, modification, change, or inducement shall be effective or given any force or effect. Contractor is, in fact and law, an independent contractor and not an agent or employee of County.\n",
            "\n",
            "üë§ Resume Summary:\n",
            " This staffing initiative is designed to deliver a team of skilled professionals who will provide comprehensive support for the development, enhancement, testing, and maintenance of high-quality software applications. The assigned staff will ensure that all software projects adhere to the highest standards of performance, functionality, and security.\n",
            "\n",
            "üìä Match Score: 50.19%\n",
            "‚ö†Ô∏è Moderate match.\n",
            "\n",
            "üìã Key Information Extracted:\n",
            "- Facilities: KernBHRS Outpatient Clinics\n",
            "- Clinics Count: 4\n",
            "- Location: Bakersfield, the\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üí¨ Ask questions about the job description (type 'quit' to stop):\n",
            "\n",
            "Answer: The facilities mentioned include: KernBHRS Outpatient Clinics, Kern County Jail, KernBHRS Crisis Stabilization Unit\n",
            "Your question: quit\n"
          ]
        }
      ],
      "source": [
        "# ‚úÖ Step 1: Install necessary packages\n",
        "\n",
        "# ‚úÖ Step 2: Define file paths directly (replace with yours)\n",
        "jd_path = \"/content/STAFF-8601.pdf\"        # Path to your Job Description PDF\n",
        "resume_path = \"/content/experience.pdf\"    # Path to your Resume/Experience PDF\n",
        "\n",
        "# ‚úÖ Step 3: Import required libraries\n",
        "import pdfplumber\n",
        "from transformers import pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import re\n",
        "\n",
        "# ‚úÖ Step 4: Utility functions\n",
        "def extract_text_from_pdf(path):\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        return \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
        "\n",
        "def extract_scope_sections(full_text):\n",
        "    lines = full_text.split('\\n')\n",
        "    relevant = []\n",
        "    capture = False\n",
        "\n",
        "    include_keywords = ['Job Description', 'Roles', 'Responsibilities', 'Scope of Work', 'Duties', 'Position Summary']\n",
        "    end_keywords = ['Qualifications', 'Requirements', 'Skills', 'Education', 'Benefits', 'Compensation']\n",
        "\n",
        "    # First pass - try to find structured sections\n",
        "    for line in lines:\n",
        "        lower = line.lower().strip()\n",
        "        if any(kw.lower() in lower for kw in include_keywords):\n",
        "            capture = True\n",
        "            relevant.append(line)  # Include the section header\n",
        "        elif capture and any(kw.lower() in lower for kw in end_keywords):\n",
        "            capture = False\n",
        "        elif capture:\n",
        "            relevant.append(line)\n",
        "\n",
        "    # If nothing was captured, return a larger portion of the document\n",
        "    if not relevant:\n",
        "        # Look for any content that appears to be descriptive\n",
        "        for line in lines:\n",
        "            if len(line.strip()) > 30 or re.search(r'(provide|perform|responsible|service|work|duty|task)', line.lower()):\n",
        "                relevant.append(line)\n",
        "\n",
        "    return \"\\n\".join(relevant) if relevant else \"\\n\".join(lines[:150])  # Return more lines if structured sections not found\n",
        "\n",
        "def summarize_text(text, model, max_chunk_words=500):\n",
        "    words = text.split()\n",
        "    if len(words) <= 100:\n",
        "        return text\n",
        "    summaries = []\n",
        "    chunk = []\n",
        "    for word in words:\n",
        "        chunk.append(word)\n",
        "        if len(chunk) >= max_chunk_words:\n",
        "            input_text = \" \".join(chunk)\n",
        "            summary = model(input_text, max_length=150, min_length=50, do_sample=False)[0]['summary_text']\n",
        "            summaries.append(summary)\n",
        "            chunk = []\n",
        "    if chunk:\n",
        "        input_text = \" \".join(chunk)\n",
        "        summary = model(input_text, max_length=150, min_length=50, do_sample=False)[0]['summary_text']\n",
        "        summaries.append(summary)\n",
        "    return \"\\n\".join(summaries)\n",
        "\n",
        "def compute_similarity(text1, text2):\n",
        "    vectorizer = TfidfVectorizer()\n",
        "    vectors = vectorizer.fit_transform([text1, text2])\n",
        "    return round(cosine_similarity(vectors[0:1], vectors[1:2])[0][0] * 100, 2)\n",
        "\n",
        "def extract_skills_from_text(text):\n",
        "    \"\"\"Extract common skills and requirements from text.\"\"\"\n",
        "    common_skills = [\n",
        "        \"python\", \"java\", \"javascript\", \"html\", \"css\", \"sql\", \"nosql\", \"aws\", \"azure\",\n",
        "        \"cloud\", \"docker\", \"kubernetes\", \"agile\", \"scrum\", \"devops\", \"ci/cd\", \"git\",\n",
        "        \"machine learning\", \"ai\", \"data analysis\", \"statistics\", \"communication\",\n",
        "        \"leadership\", \"project management\", \"problem solving\", \"analytics\", \"microsoft\",\n",
        "        \"development\", \"design\", \"testing\", \"security\", \"database\", \"programming\", \"software\",\n",
        "        \"hardware\", \"network\", \"system\", \"maintenance\", \"support\", \"administration\"\n",
        "    ]\n",
        "\n",
        "    skills_found = []\n",
        "    for skill in common_skills:\n",
        "        if re.search(r'\\b' + re.escape(skill) + r'\\b', text.lower()):\n",
        "            skills_found.append(skill)\n",
        "\n",
        "    return skills_found\n",
        "\n",
        "def extract_specific_information(text):\n",
        "    \"\"\"Extract specific information like facilities, clinics, and locations.\"\"\"\n",
        "    info = {}\n",
        "\n",
        "    # Extract clinics and facilities\n",
        "    facilities_match = re.search(r'(?:at|in)\\s+(?:the\\s+)?([^,.]*(?:Clinics?|Units?|Facilities|Centers?|Hospitals?)[^,.]*)', text, re.IGNORECASE)\n",
        "    if facilities_match:\n",
        "        facilities_text = facilities_match.group(1)\n",
        "        info['facilities'] = facilities_text.strip()\n",
        "\n",
        "    # Look for specific mentions of clinics with numbers\n",
        "    clinics_match = re.search(r'(\\d+)\\s*(?:Clinics|Outpatient\\s+Clinics)', text, re.IGNORECASE)\n",
        "    if clinics_match:\n",
        "        info['clinics_count'] = clinics_match.group(1)\n",
        "\n",
        "    # Look for locations\n",
        "    location_match = re.search(r'(?:located|location|address|based in|office in)\\s+(?:in\\s+)?([A-Z][a-zA-Z]+(?:,\\s*[A-Z][a-zA-Z]+)*)', text, re.IGNORECASE)\n",
        "    if location_match:\n",
        "        info['location'] = location_match.group(1)\n",
        "\n",
        "    # Look for service areas\n",
        "    areas_match = re.search(r'(\\d+)\\s*(?:Geographic\\s+Service\\s+Areas|Service\\s+Areas|Geographic\\s+Areas)', text, re.IGNORECASE)\n",
        "    if areas_match:\n",
        "        info['service_areas'] = areas_match.group(1)\n",
        "\n",
        "    return info\n",
        "\n",
        "# ‚úÖ Step 5: Smart Hybrid Q&A Class\n",
        "class SmartJDChatbot:\n",
        "    def __init__(self):\n",
        "        from transformers import pipeline\n",
        "        import torch\n",
        "        device = 0 if torch.cuda.is_available() else -1\n",
        "        self.generator = pipeline(\"text2text-generation\", model=\"google/flan-t5-large\", device=device)\n",
        "        from sentence_transformers import SentenceTransformer\n",
        "        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    def find_relevant_sentences(self, context, question, top_k=5):\n",
        "        from sentence_transformers import util\n",
        "        import torch\n",
        "\n",
        "        # Better sentence splitting that handles abbreviations and special cases\n",
        "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', context)\n",
        "        sentences = [s.strip() for s in sentences if len(s.strip()) > 15]\n",
        "\n",
        "        if not sentences:\n",
        "            # Fallback to simpler splitting if no sentences were extracted\n",
        "            sentences = [s.strip() for s in context.split('.') if len(s.strip()) > 15]\n",
        "\n",
        "        if not sentences:\n",
        "            return context[:500]  # Last resort fallback\n",
        "\n",
        "        sentence_embeddings = self.sentence_model.encode(sentences, convert_to_tensor=True)\n",
        "        question_embedding = self.sentence_model.encode(question, convert_to_tensor=True)\n",
        "\n",
        "        similarities = util.pytorch_cos_sim(question_embedding, sentence_embeddings)[0]\n",
        "        top_results = similarities.argsort(descending=True)[:top_k]\n",
        "\n",
        "        return \". \".join([sentences[i] for i in top_results])\n",
        "\n",
        "    def ask_question(self, context, question):\n",
        "        try:\n",
        "            q = question.strip().lower()\n",
        "\n",
        "            # Specially handle facilities and clinics questions\n",
        "            if any(keyword in q for keyword in ['clinic', 'facilit', 'hospital', 'center', 'unit']):\n",
        "                # Look specifically for mentions of clinics and other facilities\n",
        "                clinic_pattern = r'(?:KernBHRS|Kern\\s+Behavioral\\s+Health).{0,50}(?:Outpatient\\s+Clinics|Clinics)'\n",
        "                clinic_match = re.search(clinic_pattern, context, re.IGNORECASE)\n",
        "\n",
        "                jail_pattern = r'(?:Kern\\s+County\\s+Jail|County\\s+Jail)'\n",
        "                jail_match = re.search(jail_pattern, context, re.IGNORECASE)\n",
        "\n",
        "                csu_pattern = r'(?:Crisis\\s+Stabilization\\s+Unit|CSU)'\n",
        "                csu_match = re.search(csu_pattern, context, re.IGNORECASE)\n",
        "\n",
        "                facility_list = []\n",
        "                if clinic_match:\n",
        "                    facility_list.append(\"KernBHRS Outpatient Clinics\")\n",
        "                if jail_match:\n",
        "                    facility_list.append(\"Kern County Jail\")\n",
        "                if csu_match:\n",
        "                    facility_list.append(\"KernBHRS Crisis Stabilization Unit\")\n",
        "\n",
        "                if facility_list:\n",
        "                    return \"The facilities mentioned include: \" + \", \".join(facility_list)\n",
        "\n",
        "            # 1Ô∏è‚É£ Rule-based direct answers for specific question types\n",
        "            # Location questions\n",
        "            if any(word in q for word in ['where', 'location', 'address', 'based']):\n",
        "                location_pattern = r'(?:located|location|address|based in|office in).*?((?:[A-Z][a-z]+,?\\s?)+)'\n",
        "                matches = re.search(location_pattern, context, re.IGNORECASE)\n",
        "                if matches:\n",
        "                    return matches.group(0)\n",
        "\n",
        "                # Look for any city names that might indicate location\n",
        "                cities = ['Bakersfield', 'Los Angeles', 'San Francisco', 'Sacramento', 'Fresno']\n",
        "                for city in cities:\n",
        "                    if city in context:\n",
        "                        surrounding = re.search(r'[^.]*' + city + r'[^.]*\\.?', context)\n",
        "                        if surrounding:\n",
        "                            return surrounding.group(0)\n",
        "\n",
        "            # Geographic organization\n",
        "            if 'geographic' in q or 'areas' in q or 'regions' in q:\n",
        "                geo_pattern = r'(?:county|region|area).{0,50}divided into.{0,50}(?:geographic|service areas|regions)'\n",
        "                matches = re.search(geo_pattern, context, re.IGNORECASE)\n",
        "                if matches:\n",
        "                    return matches.group(0)\n",
        "\n",
        "                # Look for numbers that might indicate geographic divisions\n",
        "                number_areas = re.search(r'(\\d+).{0,20}(?:geographic|service).{0,20}(?:areas|regions)', context, re.IGNORECASE)\n",
        "                if number_areas:\n",
        "                    return number_areas.group(0)\n",
        "\n",
        "            # Facilities questions (backup approach)\n",
        "            if any(word in q for word in ['facilities', 'units', 'centers', 'clinics']) and 'how many' in q:\n",
        "                number_pattern = r'(\\d+)\\s*(?:clinics|units|facilities|centers|hospitals)'\n",
        "                matches = re.search(number_pattern, context, re.IGNORECASE)\n",
        "                if matches:\n",
        "                    return f\"There are {matches.group(1)} clinics mentioned.\"\n",
        "\n",
        "                # If no specific number is found, look for lists of facilities\n",
        "                facilities_list = re.findall(r'(?:Outpatient|KernBHRS|Department|County)\\s+(?:Clinics?|Units?|Centers?)', context, re.IGNORECASE)\n",
        "                if facilities_list:\n",
        "                    return f\"The facilities mentioned include: {', '.join(facilities_list)}\"\n",
        "\n",
        "            # Agreement questions\n",
        "            if 'agreement' in q or 'contract' in q:\n",
        "                agreement_pattern = r'(\\d+).{0,30}(?:agreements|contracts).{0,100}(?:negotiated|executed)'\n",
        "                matches = re.search(agreement_pattern, context, re.IGNORECASE)\n",
        "                if matches:\n",
        "                    return matches.group(0)\n",
        "\n",
        "            # Authority questions\n",
        "            if 'authority' in q or 'bind' in q or 'binding' in q:\n",
        "                authority_pattern = r'(?:authority|authorized).{0,100}(?:bind|binding).{0,100}(?:County|contract)'\n",
        "                matches = re.search(authority_pattern, context, re.IGNORECASE)\n",
        "                if matches:\n",
        "                    return matches.group(0)\n",
        "\n",
        "            # 2Ô∏è‚É£ Semantic retrieval\n",
        "            relevant_context = self.find_relevant_sentences(context, question)\n",
        "\n",
        "            # 3Ô∏è‚É£ Generative answer\n",
        "            prompt = f\"\"\"Based on the following job description excerpt:\n",
        "\n",
        "{relevant_context}\n",
        "\n",
        "Answer the question clearly and professionally:\n",
        "{question}\"\"\"\n",
        "            answer = self.generator(prompt, max_length=200, do_sample=False)[0]['generated_text']\n",
        "\n",
        "            # 4Ô∏è‚É£ Post-processing to enhance the answer\n",
        "            if len(answer.strip()) < 10 or \"don't know\" in answer.lower() or \"no information\" in answer.lower():\n",
        "                # Try a direct search approach\n",
        "                for facility_type in [\"clinic\", \"outpatient\", \"jail\", \"crisis\", \"stabilization\", \"unit\"]:\n",
        "                    if facility_type in q.lower():\n",
        "                        # Look for sentences containing this facility type\n",
        "                        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', context)\n",
        "                        for sentence in sentences:\n",
        "                            if facility_type in sentence.lower():\n",
        "                                return sentence.strip()\n",
        "\n",
        "                # If still no good answer, look for RFP title or header which often contains facility info\n",
        "                rfp_title = re.search(r'Request for Proposal.*?(?:provide|services).*?\\n', context, re.IGNORECASE)\n",
        "                if rfp_title:\n",
        "                    services_section = context[rfp_title.start():rfp_title.start()+500]  # Get a chunk after the title\n",
        "                    facility_mentions = re.findall(r'(?:at|in)\\s+[^.]*?(?:Clinics?|Units?|Facilities|Jail)[^.]*\\.', services_section, re.IGNORECASE)\n",
        "                    if facility_mentions:\n",
        "                        return facility_mentions[0]\n",
        "\n",
        "            return answer.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"‚ö†Ô∏è Error: {e}\"\n",
        "\n",
        "# ‚úÖ Step 6: Run the analysis\n",
        "\n",
        "# Load and summarize\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "jd_text_full = extract_text_from_pdf(jd_path)\n",
        "resume_text = extract_text_from_pdf(resume_path)\n",
        "\n",
        "jd_scope_text = extract_scope_sections(jd_text_full)\n",
        "jd_summary = summarize_text(jd_scope_text, summarizer)\n",
        "resume_summary = summarize_text(resume_text, summarizer)\n",
        "\n",
        "# Extract specific information for better context\n",
        "specific_info = extract_specific_information(jd_text_full)\n",
        "\n",
        "# Match score\n",
        "score = compute_similarity(jd_scope_text, resume_text)  # Compare full JD to resume for better matching\n",
        "\n",
        "# Extract skills for recommendation\n",
        "jd_skills = extract_skills_from_text(jd_text_full)\n",
        "resume_skills = extract_skills_from_text(resume_text)\n",
        "matching_skills = set(jd_skills).intersection(set(resume_skills))\n",
        "\n",
        "# Output\n",
        "print(\"\\nüìÑ Job Description Summary:\\n\", jd_summary)\n",
        "print(\"\\nüë§ Resume Summary:\\n\", resume_summary)\n",
        "print(f\"\\nüìä Match Score: {score}%\")\n",
        "if score >= 75:\n",
        "    print(\"‚úÖ Strong match!\")\n",
        "elif score >= 50:\n",
        "    print(\"‚ö†Ô∏è Moderate match.\")\n",
        "else:\n",
        "    print(\"‚ùå Low match. Consider highlighting these skills in your resume:\", \", \".join(set(jd_skills) - set(resume_skills)))\n",
        "\n",
        "# Display extracted specific information if available\n",
        "if specific_info:\n",
        "    print(\"\\nüìã Key Information Extracted:\")\n",
        "    for key, value in specific_info.items():\n",
        "        print(f\"- {key.replace('_', ' ').title()}: {value}\")\n",
        "\n",
        "# Q&A\n",
        "chatbot = SmartJDChatbot()\n",
        "print(\"\\nüí¨ Ask questions about the job description (type 'quit' to stop):\")\n",
        "while True:\n",
        "    question = input(\"Your question: \").strip()\n",
        "    if question.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    # For facilities/clinics questions, use a specialized approach\n",
        "    if any(keyword in question.lower() for keyword in ['clinic', 'facilit', 'hospital', 'center', 'unit', 'how many']):\n",
        "        # First try to find direct mentions in the title or first few paragraphs\n",
        "        first_500_chars = jd_text_full[:500]\n",
        "        facilities_in_title = re.search(r'(?:at|in)\\s+(?:the\\s+)?([^,.]*(?:Clinics?|Units?|Facilities|Centers?|Hospitals?|Jail)[^,.]*)', first_500_chars, re.IGNORECASE)\n",
        "\n",
        "        if facilities_in_title:\n",
        "            answer = \"The facilities mentioned include: \" + facilities_in_title.group(1)\n",
        "            # Look for more specific mentions later in the text\n",
        "            additional = []\n",
        "            if \"clinic\" in jd_text_full.lower():\n",
        "                additional.append(\"KernBHRS Outpatient Clinics\")\n",
        "            if \"jail\" in jd_text_full.lower():\n",
        "                additional.append(\"Kern County Jail\")\n",
        "            if \"crisis\" in jd_text_full.lower() and \"unit\" in jd_text_full.lower():\n",
        "                additional.append(\"Crisis Stabilization Unit\")\n",
        "\n",
        "            if additional:\n",
        "                answer += \"\\nSpecifically: \" + \", \".join(additional)\n",
        "        else:\n",
        "            answer = chatbot.ask_question(jd_text_full, question)\n",
        "    else:\n",
        "        answer = chatbot.ask_question(jd_text_full, question)\n",
        "\n",
        "    print(\"\\nAnswer:\", answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EREfHGw2ZGpo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfyVqxwhMTSaP5wGRdgit5",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
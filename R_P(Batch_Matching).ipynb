{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XySH27gdmnasQw1r5-VXaIurkKWlDqD_",
      "authorship_tag": "ABX9TyPQfHeBp9xI1gWxiFvLCLXI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cherypallysaisurya/ResuVerse/blob/main/R_P(Batch_Matching).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy langchain\n",
        "!python -m spacy download en_core_web_lg\n",
        "!pip install transformers python-docx PyPDF2 Pillow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POBPAepVBd1r",
        "outputId": "af9342a3-028a-474d-b3b0-bc39add435c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.5)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.49)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.22)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (4.13.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.1)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Collecting en-core-web-lg==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.8.0/en_core_web_lg-3.8.0-py3-none-any.whl (400.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.7/400.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.1)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx, PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1 python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSCsSwscBZGn",
        "outputId": "f66dd642-a405-4e02-f043-6a769ec151ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the path to the resume directory: /content/test\n",
            "Enter the job description: Enlyte is the parent brand of Mitchell, Genex and Coventry, an organization unlike any other in the Property & Casualty industry, bringing together three great businesses with a shared vision of using technology innovation, clinical services and network solutions to help our customers and the people they serve. Our suite of products and services enable our employees to help people recover from challenging life events, while providing opportunities for meaningful impact and career growth.    Responsibilities  We are building next generation suite of smart product solutions using Computer Vision, Advanced Analytics and Artificial Intelligence [Deep Learning]. We are looking for engineers and technologists to help build the next generation of systems, tools and features for our cutting-edge products and platforms that support millions of transactions. This team is the focal point in our work, bringing the latest in search and discovery ideas to production on a large scale.  As a remote Machine Learning Data Scientist Intern, you will have the opportunity to solve challenging problems or build predictive models across a broad range of products. You will apply machine learning techniques to improve our algorithms, workflows and core products to become more predictive. You will partner with engineers to implement your ideas in production and analysts to evaluate and validate your improvements. Interns will be working on real projects and products that are customer-facing.  You will have opportunity to work on several challenging Machine Learning problems, including  How to build models at scale using vast amounts of structured and unstructured heterogeneous types of data.Ensuring high accuracy based on industry's stringent requirements around precision or recall and with minimum Type I and Type II errors.Generating predictions for millions of rows of data with high response timeDealing with high data diversity (vast amounts of data will need to be classified and will have multi labelled outcomes) Dealing with very high dimensionality (expect to work on large matrix computations, variable transformation & feature engineering and selection using PCA and other novel ML techniques)Dealing with noisy data (build models robust enough for unclassified and/or mislabeled data)  Qualifications  Minimum Qualifications:  Pursuing a bachelor's or master's degree in Mathematics, Computer Science, Data Science, or related degreeGPA of 3.0 or higherGraduating between Summer 2025 and Summer 2026Good understanding of machine learning theory, Artificial Intelligence [Deep Learning] and algorithms, such as CNNs, k-NN, Naive Bayes, SVM, Decision Forests, Ensembles, Decisions TreesCoding skills and knowledge around using scientific, distributed programming and scripting languages like R, Python, Pyspark and/or Java preferredFoundation in statistics and machine learning algorithmsFamiliarity of modern statistical learning methods & machine learning Frameworks like H2O, Spark & HadoopKnowledge on how to build prototypes and be able to understand the existing code baseA principled approach to solving algorithmic problems with a focus on what will make users happyA pragmatic approach to rapidly evaluating new algorithmic ideasA very high attention to detail and ability to thoroughly think through problemsExcellent written and oral communication skills on both technical and non-technical topicsAbility to commit 40 hours per week for 12 weeks during the 2025 summerWorking PST or CST time zones preferred, but not required\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e9fa97f4092d>:85: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
            "  if skill_doc.similarity(chunk) > 0.85:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Resume Ranking Results ===\n",
            "\n",
            "Rank 1: Sai_surya_rakuten.pdf\n",
            "Similarity Score: 27.5%\n",
            "Skill Match Ratio: 16.79%\n",
            "Fit for Position: No\n",
            "\n",
            "Matching Skills:\n",
            "  ✓ tools\n",
            "  ✓ deep learning\n",
            "  ✓ machine learning theory\n",
            "  ✓ ability\n",
            "  ✓ computer vision\n",
            "  ✓ predictive models\n",
            "  ✓ techniques\n",
            "  ✓ deep\n",
            "  ✓ data\n",
            "  ✓ understanding\n",
            "  ✓ models\n",
            "  ✓ systems\n",
            "  ✓ communication skills\n",
            "  ✓ cnns\n",
            "  ✓ machine learning techniques\n",
            "  ✓ python\n",
            "  ✓ r\n",
            "  ✓ advanced analytics\n",
            "  ✓ treescoding skills\n",
            "  ✓ learning\n",
            "  ✓ master s degree\n",
            "  ✓ data science\n",
            "  ✓ machine learning\n",
            "\n",
            "Missing Skills:\n",
            "  ✗ computer science\n",
            "  ✗ genex\n",
            "  ✗ high data diversity\n",
            "  ✗ errors.generating predictions\n",
            "  ✗ recall\n",
            "  ✗ selection\n",
            "  ✗ platforms\n",
            "  ✗ opportunity\n",
            "  ✗ generation suite\n",
            "  ✗ data diversity\n",
            "  ✗ ensembles\n",
            "  ✗ mathematics\n",
            "  ✗ our customers\n",
            "  ✗ decisions\n",
            "  ✗ high response\n",
            "  ✗ opportunities\n",
            "  ✗ related degreegpa\n",
            "  ✗ build models\n",
            "  ✗ algorithms\n",
            "  ✗ life events\n",
            "  ✗ property casualty\n",
            "  ✗ engineers\n",
            "  ✗ new algorithmic ideasa\n",
            "  ✗ labelled outcomes\n",
            "  ✗ people\n",
            "  ✗ large matrix computations\n",
            "  ✗ career growth\n",
            "  ✗ products\n",
            "  ✗ hadoopknowledge\n",
            "  ✗ our algorithms\n",
            "  ✗ core products\n",
            "  ✗ pragmatic approach\n",
            "  ✗ feature engineering\n",
            "  ✗ enlyte\n",
            "  ✗ next generation suite\n",
            "  ✗ services\n",
            "  ✗ data qualifications\n",
            "  ✗ vast amounts\n",
            "  ✗ summer\n",
            "  ✗ features\n",
            "  ✗ users\n",
            "  ✗ your improvements\n",
            "  ✗ artificial intelligence\n",
            "  ✗ bachelor s\n",
            "  ✗ mitchell\n",
            "  ✗ responsibilities\n",
            "  ✗ pca\n",
            "  ✗ algorithmic problems\n",
            "  ✗ network solutions\n",
            "  ✗ our suite\n",
            "  ✗ casualty industry\n",
            "  ✗ matrix computations\n",
            "  ✗ minimum qualifications\n",
            "  ✗ week\n",
            "  ✗ production\n",
            "  ✗ coventry\n",
            "  ✗ our employees\n",
            "  ✗ product solutions\n",
            "  ✗ transactions\n",
            "  ✗ algorithmsfamiliarity\n",
            "  ✗ millions\n",
            "  ✗ java preferredfoundation\n",
            "  ✗ cst time\n",
            "  ✗ edge products\n",
            "  ✗ data.ensuring high accuracy\n",
            "  ✗ scientist intern\n",
            "  ✗ transformation engineering\n",
            "  ✗ java\n",
            "  ✗ prototypes\n",
            "  ✗ data scientist intern\n",
            "  ✗ cst time zones\n",
            "  ✗ learning theory\n",
            "  ✗ decision forests\n",
            "  ✗ precision\n",
            "  ✗ clinical services\n",
            "  ✗ data scientist\n",
            "  ✗ challenging problems\n",
            "  ✗ scale\n",
            "  ✗ ii\n",
            "  ✗ learning methods\n",
            "  ✗ real projects\n",
            "  ✗ type i\n",
            "  ✗ statistics\n",
            "  ✗ h2o\n",
            "  ✗ smart product solutions\n",
            "  ✗ three great businesses\n",
            "  ✗ analysts\n",
            "  ✗ learning problems\n",
            "  ✗ summer 2026good\n",
            "  ✗ interns\n",
            "  ✗ learning frameworks\n",
            "  ✗ type ii\n",
            "  ✗ 40 hours\n",
            "  ✗ meaningful impact\n",
            "  ✗ rows\n",
            "  ✗ cst\n",
            "  ✗ knowledge\n",
            "  ✗ 12 weeks\n",
            "  ✗ technologists\n",
            "  ✗ detail\n",
            "  ✗ very high dimensionality\n",
            "  ✗ other novel ml\n",
            "  ✗ workflows\n",
            "  ✗ pyspark\n",
            "  ✗ methods frameworks\n",
            "  ✗ our cutting-edge products\n",
            "  ✗ our work\n",
            "  ✗ time zones\n",
            "  ✗ your ideas\n",
            "  ✗ very high attention\n",
            "  ✗ data build\n",
            "  ✗ parent brand\n",
            "  ✗ technology innovation\n",
            "  ✗ learning techniques\n",
            "--------------------------------------------------\n",
            "\n",
            "Rank 2: SURYA_RESUME.pdf\n",
            "Similarity Score: 21.95%\n",
            "Skill Match Ratio: 16.06%\n",
            "Fit for Position: No\n",
            "\n",
            "Matching Skills:\n",
            "  ✓ computer science\n",
            "  ✓ machine learning theory\n",
            "  ✓ ability\n",
            "  ✓ java preferredfoundation\n",
            "  ✓ feature engineering\n",
            "  ✓ predictive models\n",
            "  ✓ techniques\n",
            "  ✓ data\n",
            "  ✓ java\n",
            "  ✓ models\n",
            "  ✓ systems\n",
            "  ✓ communication skills\n",
            "  ✓ data scientist intern\n",
            "  ✓ workflows\n",
            "  ✓ data scientist\n",
            "  ✓ machine learning techniques\n",
            "  ✓ python\n",
            "  ✓ r\n",
            "  ✓ treescoding skills\n",
            "  ✓ learning\n",
            "  ✓ data science\n",
            "  ✓ machine learning\n",
            "\n",
            "Missing Skills:\n",
            "  ✗ deep learning\n",
            "  ✗ genex\n",
            "  ✗ high data diversity\n",
            "  ✗ errors.generating predictions\n",
            "  ✗ recall\n",
            "  ✗ selection\n",
            "  ✗ platforms\n",
            "  ✗ opportunity\n",
            "  ✗ generation suite\n",
            "  ✗ data diversity\n",
            "  ✗ ensembles\n",
            "  ✗ deep\n",
            "  ✗ mathematics\n",
            "  ✗ our customers\n",
            "  ✗ decisions\n",
            "  ✗ high response\n",
            "  ✗ opportunities\n",
            "  ✗ related degreegpa\n",
            "  ✗ build models\n",
            "  ✗ algorithms\n",
            "  ✗ life events\n",
            "  ✗ property casualty\n",
            "  ✗ engineers\n",
            "  ✗ new algorithmic ideasa\n",
            "  ✗ labelled outcomes\n",
            "  ✗ people\n",
            "  ✗ large matrix computations\n",
            "  ✗ master s degree\n",
            "  ✗ career growth\n",
            "  ✗ products\n",
            "  ✗ hadoopknowledge\n",
            "  ✗ our algorithms\n",
            "  ✗ core products\n",
            "  ✗ pragmatic approach\n",
            "  ✗ enlyte\n",
            "  ✗ next generation suite\n",
            "  ✗ services\n",
            "  ✗ data qualifications\n",
            "  ✗ vast amounts\n",
            "  ✗ summer\n",
            "  ✗ features\n",
            "  ✗ users\n",
            "  ✗ your improvements\n",
            "  ✗ artificial intelligence\n",
            "  ✗ bachelor s\n",
            "  ✗ mitchell\n",
            "  ✗ responsibilities\n",
            "  ✗ pca\n",
            "  ✗ algorithmic problems\n",
            "  ✗ network solutions\n",
            "  ✗ our suite\n",
            "  ✗ casualty industry\n",
            "  ✗ matrix computations\n",
            "  ✗ minimum qualifications\n",
            "  ✗ week\n",
            "  ✗ advanced analytics\n",
            "  ✗ production\n",
            "  ✗ coventry\n",
            "  ✗ our employees\n",
            "  ✗ product solutions\n",
            "  ✗ tools\n",
            "  ✗ transactions\n",
            "  ✗ algorithmsfamiliarity\n",
            "  ✗ millions\n",
            "  ✗ cst time\n",
            "  ✗ edge products\n",
            "  ✗ data.ensuring high accuracy\n",
            "  ✗ computer vision\n",
            "  ✗ scientist intern\n",
            "  ✗ transformation engineering\n",
            "  ✗ understanding\n",
            "  ✗ prototypes\n",
            "  ✗ cst time zones\n",
            "  ✗ learning theory\n",
            "  ✗ decision forests\n",
            "  ✗ precision\n",
            "  ✗ clinical services\n",
            "  ✗ challenging problems\n",
            "  ✗ scale\n",
            "  ✗ ii\n",
            "  ✗ learning methods\n",
            "  ✗ real projects\n",
            "  ✗ type i\n",
            "  ✗ statistics\n",
            "  ✗ h2o\n",
            "  ✗ smart product solutions\n",
            "  ✗ three great businesses\n",
            "  ✗ analysts\n",
            "  ✗ learning problems\n",
            "  ✗ summer 2026good\n",
            "  ✗ interns\n",
            "  ✗ learning frameworks\n",
            "  ✗ type ii\n",
            "  ✗ 40 hours\n",
            "  ✗ meaningful impact\n",
            "  ✗ rows\n",
            "  ✗ cst\n",
            "  ✗ knowledge\n",
            "  ✗ 12 weeks\n",
            "  ✗ technologists\n",
            "  ✗ detail\n",
            "  ✗ cnns\n",
            "  ✗ very high dimensionality\n",
            "  ✗ other novel ml\n",
            "  ✗ pyspark\n",
            "  ✗ methods frameworks\n",
            "  ✗ our cutting-edge products\n",
            "  ✗ our work\n",
            "  ✗ time zones\n",
            "  ✗ your ideas\n",
            "  ✗ very high attention\n",
            "  ✗ data build\n",
            "  ✗ parent brand\n",
            "  ✗ technology innovation\n",
            "  ✗ learning techniques\n",
            "--------------------------------------------------\n",
            "\n",
            "Detailed results saved to resume_ranking_20250407_022440.json\n",
            "\n",
            "=== Best Matching Resume ===\n",
            "Filename: Sai_surya_rakuten.pdf\n",
            "Similarity Score: 27.5%\n",
            "Skill Match Ratio: 16.79%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import logging\n",
        "import json\n",
        "from typing import Dict, Tuple, Set, List\n",
        "from docx import Document\n",
        "from PyPDF2 import PdfReader\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from datetime import datetime\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "\n",
        "class ResumeAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "    def extract_text(self, file_path: str) -> str:\n",
        "        \"\"\"Extract text from PDF or DOCX files\"\"\"\n",
        "        try:\n",
        "            if file_path.endswith(\".pdf\"):\n",
        "                reader = PdfReader(file_path)\n",
        "                text = []\n",
        "                for page in reader.pages:\n",
        "                    page_text = page.extract_text()\n",
        "                    if page_text:\n",
        "                        text.append(page_text)\n",
        "                return \"\\n\".join(text)\n",
        "            elif file_path.endswith(\".docx\"):\n",
        "                doc = Document(file_path)\n",
        "                return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error extracting text from {file_path}: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        \"\"\"Clean and preprocess text\"\"\"\n",
        "        text = re.sub(r\"\\S+@\\S+\", \"\", text)  # Remove emails\n",
        "        text = re.sub(r\"\\(?\\d{3}\\)?[\\s-]?\\d{3}[\\s-]?\\d{3,4}\", \"\", text)  # Remove phone numbers\n",
        "        text = re.sub(r\"[^\\w\\s.,-:]\", \" \", text)  # Remove special characters\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize whitespace\n",
        "        return text.lower()\n",
        "\n",
        "    def extract_skills_from_job_description(self, text: str) -> Set[str]:\n",
        "        \"\"\"Extract skills from job description using NLP\"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        skills = set()\n",
        "\n",
        "        for chunk in doc.noun_chunks:\n",
        "            skill = chunk.text.lower().strip()\n",
        "            if (len(skill.split()) <= 3 and len(skill) >= 3 and\n",
        "                not any(word.text.lower() in [\"the\", \"a\", \"an\", \"this\", \"that\", \"these\", \"those\"]\n",
        "                        for word in chunk) and not chunk.root.pos_ in [\"PRON\", \"DET\", \"ADP\"]):\n",
        "                skills.add(skill)\n",
        "\n",
        "        for token in doc:\n",
        "            if token.pos_ in [\"PROPN\"] or (token.text.isupper() and len(token.text) >= 2):\n",
        "                skills.add(token.text.lower())\n",
        "\n",
        "        for token in doc:\n",
        "            if token.dep_ == \"compound\":\n",
        "                compound = \" \".join([token.text, token.head.text]).lower()\n",
        "                if len(compound.split()) <= 3:\n",
        "                    skills.add(compound)\n",
        "\n",
        "        return skills\n",
        "\n",
        "    def find_matching_skills(self, text: str, required_skills: Set[str]) -> Set[str]:\n",
        "        \"\"\"Find matching skills in resume\"\"\"\n",
        "        doc = self.nlp(text)\n",
        "        found_skills = set()\n",
        "        text_lower = text.lower()\n",
        "\n",
        "        for skill in required_skills:\n",
        "            if skill.lower() in text_lower:\n",
        "                found_skills.add(skill)\n",
        "                continue\n",
        "\n",
        "            skill_doc = self.nlp(skill)\n",
        "            for chunk in doc.noun_chunks:\n",
        "                if skill_doc.similarity(chunk) > 0.85:\n",
        "                    found_skills.add(skill)\n",
        "                    break\n",
        "\n",
        "        return found_skills\n",
        "\n",
        "    def calculate_cosine_similarity(self, text1: str, text2: str) -> float:\n",
        "        \"\"\"Compute cosine similarity between two texts\"\"\"\n",
        "        vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "        tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
        "        similarity_score = float(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0])\n",
        "        return similarity_score\n",
        "\n",
        "    def analyze_resume(self, resume_text: str, job_description: str, filename: str) -> Dict:\n",
        "        \"\"\"Analyze resume against job description\"\"\"\n",
        "        required_skills = self.extract_skills_from_job_description(job_description)\n",
        "        matching_skills = self.find_matching_skills(resume_text, required_skills)\n",
        "        missing_skills = required_skills - matching_skills\n",
        "\n",
        "        similarity_score = self.calculate_cosine_similarity(resume_text, job_description)\n",
        "\n",
        "        skill_match_ratio = len(matching_skills) / len(required_skills) if required_skills else 0\n",
        "        is_fit = skill_match_ratio >= 0.7 and similarity_score > 0.6\n",
        "\n",
        "        return {\n",
        "            \"filename\": filename,\n",
        "            \"similarity_score\": round(similarity_score * 100, 2),\n",
        "            \"skill_match_ratio\": round(skill_match_ratio * 100, 2),\n",
        "            \"matching_skills\": list(matching_skills),\n",
        "            \"missing_skills\": list(missing_skills),\n",
        "            \"is_fit\": is_fit\n",
        "        }\n",
        "\n",
        "    def process_multiple_resumes(self, resume_dir: str, job_description: str) -> List[Dict]:\n",
        "        \"\"\"Process and rank multiple resumes\"\"\"\n",
        "        results = []\n",
        "\n",
        "        job_description = self.preprocess_text(job_description)\n",
        "\n",
        "        for filename in os.listdir(resume_dir):\n",
        "            if filename.endswith((\".pdf\", \".docx\")):\n",
        "                try:\n",
        "                    file_path = os.path.join(resume_dir, filename)\n",
        "                    resume_text = self.extract_text(file_path)\n",
        "                    resume_text = self.preprocess_text(resume_text)\n",
        "\n",
        "                    resume_analysis = self.analyze_resume(resume_text, job_description, filename)\n",
        "                    results.append(resume_analysis)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "        results.sort(key=lambda x: (x[\"similarity_score\"], x[\"skill_match_ratio\"]), reverse=True)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    analyzer = ResumeAnalyzer()\n",
        "    resume_dir = input(\"Enter the path to the resume directory: \").strip()\n",
        "    job_description = input(\"Enter the job description: \").strip()\n",
        "\n",
        "    try:\n",
        "        ranked_resumes = analyzer.process_multiple_resumes(resume_dir, job_description)\n",
        "\n",
        "        print(\"\\n=== Resume Ranking Results ===\")\n",
        "        for rank, resume in enumerate(ranked_resumes, 1):\n",
        "            print(f\"\\nRank {rank}: {resume['filename']}\")\n",
        "            print(f\"Similarity Score: {resume['similarity_score']}%\")\n",
        "            print(f\"Skill Match Ratio: {resume['skill_match_ratio']}%\")\n",
        "            print(f\"Fit for Position: {'Yes' if resume['is_fit'] else 'No'}\")\n",
        "\n",
        "            print(\"\\nMatching Skills:\")\n",
        "            for skill in resume[\"matching_skills\"]:\n",
        "                print(f\"  ✓ {skill}\")\n",
        "\n",
        "            print(\"\\nMissing Skills:\")\n",
        "            for skill in resume[\"missing_skills\"]:\n",
        "                print(f\"  ✗ {skill}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        output_file = f\"resume_ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(ranked_resumes, f, indent=2)\n",
        "\n",
        "        print(f\"\\nDetailed results saved to {output_file}\")\n",
        "\n",
        "        if ranked_resumes:\n",
        "            best_resume = ranked_resumes[0]\n",
        "            print(\"\\n=== Best Matching Resume ===\")\n",
        "            print(f\"Filename: {best_resume['filename']}\")\n",
        "            print(f\"Similarity Score: {best_resume['similarity_score']}%\")\n",
        "            print(f\"Skill Match Ratio: {best_resume['skill_match_ratio']}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import logging\n",
        "import json\n",
        "from typing import Dict, Tuple, Set, List\n",
        "from docx import Document\n",
        "from PyPDF2 import PdfReader\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from datetime import datetime\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "\n",
        "class ResumeAnalyzer:\n",
        "    def __init__(self):\n",
        "        self.nlp = spacy.load(\"en_core_web_lg\")\n",
        "\n",
        "    def extract_text(self, file_path: str) -> str:\n",
        "        \"\"\"Extract text from PDF or DOCX files\"\"\"\n",
        "        try:\n",
        "            if file_path.endswith(\".pdf\"):\n",
        "                reader = PdfReader(file_path)\n",
        "                text = [page.extract_text() for page in reader.pages if page.extract_text()]\n",
        "                return \"\\n\".join(text)\n",
        "            elif file_path.endswith(\".docx\"):\n",
        "                doc = Document(file_path)\n",
        "                return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported file format: {file_path}\")\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error extracting text from {file_path}: {str(e)}\")\n",
        "            return \"\"\n",
        "\n",
        "    def preprocess_text(self, text: str) -> str:\n",
        "        \"\"\"Clean and preprocess text\"\"\"\n",
        "        text = re.sub(r\"\\S+@\\S+\", \"\", text)  # Remove emails\n",
        "        text = re.sub(r\"\\(?\\d{3}\\)?[\\s-]?\\d{3}[\\s-]?\\d{3,4}\", \"\", text)  # Remove phone numbers\n",
        "        text = re.sub(r\"[^\\w\\s.,-:]\", \" \", text)  # Remove special characters\n",
        "        text = re.sub(r\"\\s+\", \" \", text).strip()  # Normalize whitespace\n",
        "        return text.lower()\n",
        "\n",
        "    def extract_relevant_skills(self, text: str) -> Set[str]:\n",
        "        \"\"\"Extract technical skills using regex + NLP filtering\"\"\"\n",
        "        # Predefined regex-based technical skill patterns\n",
        "        skill_patterns = re.findall(\n",
        "            r\"\\b(JavaScript|ReactJS|Python|Java|C\\+\\+|C#|TypeScript|SQL|T-SQL|.NET|ASP\\.NET|\"\n",
        "            r\"Node\\.js|Azure|AWS|DevOps|OAuth2|JWT|REST|SOAP|GraphQL|Jenkins|Kubernetes|Docker|\"\n",
        "            r\"Spring Boot|MongoDB|PostgreSQL|MySQL|Visual Studio|TFS|CI/CD|Agile|Jira|Scrum)\\b\",\n",
        "            text, re.IGNORECASE\n",
        "        )\n",
        "\n",
        "        # Extract skills using NLP noun-chunk filtering\n",
        "        doc = self.nlp(text)\n",
        "        extracted_skills = {token.text.lower() for token in doc if token.pos_ in {\"NOUN\", \"PROPN\"}}\n",
        "\n",
        "        # Filter out generic terms and keep relevant ones\n",
        "        final_skills = {skill.lower() for skill in skill_patterns}.union(extracted_skills)\n",
        "        return final_skills\n",
        "\n",
        "    def find_matching_skills(self, resume_text: str, job_description: str) -> Tuple[Set[str], Set[str]]:\n",
        "        \"\"\"Find and match only relevant job skills\"\"\"\n",
        "        required_skills = self.extract_relevant_skills(job_description)\n",
        "        resume_skills = self.extract_relevant_skills(resume_text)\n",
        "\n",
        "        matching_skills = resume_skills.intersection(required_skills)\n",
        "        missing_skills = required_skills - matching_skills\n",
        "\n",
        "        return matching_skills, missing_skills\n",
        "\n",
        "    def calculate_cosine_similarity(self, text1: str, text2: str) -> float:\n",
        "        \"\"\"Compute cosine similarity between two texts\"\"\"\n",
        "        vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "        tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
        "        return float(cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0])\n",
        "\n",
        "    def analyze_resume(self, resume_text: str, job_description: str, filename: str) -> Dict:\n",
        "        \"\"\"Analyze resume against job description\"\"\"\n",
        "        matching_skills, missing_skills = self.find_matching_skills(resume_text, job_description)\n",
        "        similarity_score = self.calculate_cosine_similarity(resume_text, job_description)\n",
        "\n",
        "        skill_match_ratio = len(matching_skills) / len(matching_skills.union(missing_skills)) if missing_skills else 1\n",
        "        is_fit = skill_match_ratio >= 0.7 and similarity_score > 0.6\n",
        "\n",
        "        return {\n",
        "            \"filename\": filename,\n",
        "            \"similarity_score\": round(similarity_score * 100, 2),\n",
        "            \"skill_match_ratio\": round(skill_match_ratio * 100, 2),\n",
        "            \"matching_skills\": list(matching_skills),\n",
        "            \"missing_skills\": list(missing_skills),\n",
        "            \"is_fit\": is_fit\n",
        "        }\n",
        "\n",
        "    def process_multiple_resumes(self, resume_dir: str, job_description: str) -> List[Dict]:\n",
        "        \"\"\"Process and rank multiple resumes\"\"\"\n",
        "        results = []\n",
        "        job_description = self.preprocess_text(job_description)\n",
        "\n",
        "        for filename in os.listdir(resume_dir):\n",
        "            if filename.endswith((\".pdf\", \".docx\")):\n",
        "                try:\n",
        "                    file_path = os.path.join(resume_dir, filename)\n",
        "                    resume_text = self.extract_text(file_path)\n",
        "                    resume_text = self.preprocess_text(resume_text)\n",
        "\n",
        "                    resume_analysis = self.analyze_resume(resume_text, job_description, filename)\n",
        "                    results.append(resume_analysis)\n",
        "\n",
        "                except Exception as e:\n",
        "                    logging.error(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "        results.sort(key=lambda x: (x[\"similarity_score\"], x[\"skill_match_ratio\"]), reverse=True)\n",
        "        return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    analyzer = ResumeAnalyzer()\n",
        "    resume_dir = input(\"Enter the path to the resume directory: \").strip()\n",
        "    job_description = input(\"Enter the job description: \").strip()\n",
        "\n",
        "    try:\n",
        "        ranked_resumes = analyzer.process_multiple_resumes(resume_dir, job_description)\n",
        "\n",
        "        print(\"\\n=== Resume Ranking Results ===\")\n",
        "        for rank, resume in enumerate(ranked_resumes, 1):\n",
        "            print(f\"\\nRank {rank}: {resume['filename']}\")\n",
        "            print(f\"Similarity Score: {resume['similarity_score']}%\")\n",
        "            print(f\"Skill Match Ratio: {resume['skill_match_ratio']}%\")\n",
        "            print(f\"Fit for Position: {'Yes' if resume['is_fit'] else 'No'}\")\n",
        "\n",
        "            print(\"\\nMatching Skills:\")\n",
        "            for skill in resume[\"matching_skills\"]:\n",
        "                print(f\"  ✓ {skill}\")\n",
        "\n",
        "            print(\"\\nMissing Skills:\")\n",
        "            for skill in resume[\"missing_skills\"]:\n",
        "                print(f\"  ✗ {skill}\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        output_file = f\"resume_ranking_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(ranked_resumes, f, indent=2)\n",
        "\n",
        "        print(f\"\\nDetailed results saved to {output_file}\")\n",
        "\n",
        "        if ranked_resumes:\n",
        "            best_resume = ranked_resumes[0]\n",
        "            print(\"\\n=== Best Matching Resume ===\")\n",
        "            print(f\"Filename: {best_resume['filename']}\")\n",
        "            print(f\"Similarity Score: {best_resume['similarity_score']}%\")\n",
        "            print(f\"Skill Match Ratio: {best_resume['skill_match_ratio']}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0pAfn37brHJ",
        "outputId": "db7b0c7f-abbc-4f71-aae4-2e849acf165d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the path to the resume directory: /content/drive/MyDrive/resumes\n",
            "Enter the job description: Posting Title: Software Developer - .NET and ReactJS The role of the Software Developer is to assist in providing technical and operational support to projects and programs. This role involves working under direct supervision to maintains, adapts and updates existing systems to meet user requirements and to enhance program efficiency. Acentra Health supports a high-volume healthcare data system that is accessed through multiple web portals.  What you will do: •\tMaintains, adapts, and updates existing systems to meet user requirements and to enhance program efficiency. Researches and documents user requirements and system specifications. •\tDesigns and develops program logic addressing specific programming needs. Translates business requirements and functional specifications into detailed system and program design specifications. Assumes responsibility for program design activities including definition of data and error message arrangements. •\tModifies and documents new and existing program code to correct errors or to enhance a program's capabilities. Creates/troubleshoots program code for the existing applications using Acentra Health selected software development tools. •\tPrepares lifecycle documentation for newly created and existing software programs including changes that reflect new user requirements and error corrections/bugs discovered after the testing phase. Prepares reports on the status, operation, and maintenance of system software for use by computer equipment suppliers, systems designers, other programmers, and computer operators. •\tTest programs, new and existing, to ensure they perform as expected. Helps develop, document, and implement system designs, codes, and testing standards. Analyzes proposed changes at a system level and recommends designs and solutions that minimize impact to interfacing systems while maximizing code re-usability and maintaining business value. •\tWorks in coordination with other software engineers on larger projects. •\tOther duties as assigned.  Who you are: •\tHave a bachelor’s degree with a minimum of 4+ years of relevant work experience. •\tExperience in performing all functions of computer programming, using standard design and programming techniques; developing of .NET applications preferred. •\t3+ years of strong experience with ReactJS with Typescript. •\tStrong experience developing with C# .NET 4.8 and higher technologies. •\tStrong experience in relational database concepts and experience in T-SQL. •\tKnowledge and demonstrable experience in HTTP, ASP.NET, MVC.NET, HTML5, CSS, jQuery. •\tKnowledge and demonstrable experience in ASP.NET Web API, JWT, OAuth2, JSON, REST, SOAP. •\tKnowledge and demonstrable experience in Entity Framework 6 through EF Core. •\tExperience using the most recent versions of Visual Studio, SQL Server Management Studio, TFS/Azure DevOps. •\tKnowledge of systems development lifecycle and/or operational maintenance environment. •\tExcellent oral and written technical, business, and user communication skills. •\tTeam player with strong interpersonal skills, detail-oriented, and capable of working cross-functionally within the organization. •\tAbility to write routine reports and correspondence. •\tExcellent problem-solving skills, particularly in anticipating and solving problems, issues, or concerns before they occur or become critical. •\tAbility to read and interpret documents such as safety rules, procedure manuals, operation, and maintenance instructions. •\tAbility to solve practical problems and deal with a variety of concrete variables in situations where only limited standardization exists. •\tAbility to interpret a variety of instructions provided in written, oral, diagram, or schedule form including the aptitude to take non-technical requirements and convert them into technical requirements. •\tAbility to create coded unit tests.\n",
            "\n",
            "=== Resume Ranking Results ===\n",
            "\n",
            "Rank 1: saisurya.docx\n",
            "Similarity Score: 13.11%\n",
            "Skill Match Ratio: 21.48%\n",
            "Fit for Position: No\n",
            "\n",
            "Matching Skills:\n",
            "  ✓ design\n",
            "  ✓ css\n",
            "  ✓ standards\n",
            "  ✓ concepts\n",
            "  ✓ projects\n",
            "  ✓ software\n",
            "  ✓ web\n",
            "  ✓ programming\n",
            "  ✓ sql\n",
            "  ✓ knowledge\n",
            "  ✓ development\n",
            "  ✓ c\n",
            "  ✓ team\n",
            "  ✓ tools\n",
            "  ✓ role\n",
            "  ✓ techniques\n",
            "  ✓ communication\n",
            "  ✓ experience\n",
            "  ✓ data\n",
            "  ✓ ability\n",
            "  ✓ database\n",
            "  ✓ environment\n",
            "  ✓ skills\n",
            "  ✓ system\n",
            "  ✓ bachelor\n",
            "  ✓ documentation\n",
            "  ✓ detail\n",
            "  ✓ problem\n",
            "  ✓ technologies\n",
            "  ✓ core\n",
            "  ✓ efficiency\n",
            "  ✓ program\n",
            "\n",
            "Missing Skills:\n",
            "  ✗ systems\n",
            "  ✗ work\n",
            "  ✗ maintains\n",
            "  ✗ responsibility\n",
            "  ✗ engineers\n",
            "  ✗ variables\n",
            "  ✗ reactjs\n",
            "  ✗ troubleshoots\n",
            "  ✗ code\n",
            "  ✗ unit\n",
            "  ✗ health\n",
            "  ✗ http\n",
            "  ✗ business\n",
            "  ✗ reports\n",
            "  ✗ portals\n",
            "  ✗ versions\n",
            "  ✗ acentra\n",
            "  ✗ lifecycle\n",
            "  ✗ adapts\n",
            "  ✗ needs\n",
            "  ✗ concerns\n",
            "  ✗ instructions\n",
            "  ✗ usability\n",
            "  ✗ volume\n",
            "  ✗ healthcare\n",
            "  ✗ specifications\n",
            "  ✗ -\n",
            "  ✗ operation\n",
            "  ✗ standardization\n",
            "  ✗ developer\n",
            "  ✗ supervision\n",
            "  ✗ test\n",
            "  ✗ solutions\n",
            "  ✗ coordination\n",
            "  ✗ equipment\n",
            "  ✗ researches\n",
            "  ✗ functions\n",
            "  ✗ asp.net\n",
            "  ✗ logic\n",
            "  ✗ codes\n",
            "  ✗ applications\n",
            "  ✗ entity\n",
            "  ✗ bugs\n",
            "  ✗ studio\n",
            "  ✗ requirements\n",
            "  ✗ capabilities\n",
            "  ✗ user\n",
            "  ✗ use\n",
            "  ✗ .net\n",
            "  ✗ organization\n",
            "  ✗ years\n",
            "  ✗ azure\n",
            "  ✗ support\n",
            "  ✗ t\n",
            "  ✗ changes\n",
            "  ✗ correspondence\n",
            "  ✗ suppliers\n",
            "  ✗ mvc.net\n",
            "  ✗ form\n",
            "  ✗ schedule\n",
            "  ✗ situations\n",
            "  ✗ value\n",
            "  ✗ computer\n",
            "  ✗ title\n",
            "  ✗ phase\n",
            "  ✗ aptitude\n",
            "  ✗ corrections\n",
            "  ✗ jquery\n",
            "  ✗ designers\n",
            "  ✗ tests\n",
            "  ✗ tfs\n",
            "  ✗ typescript\n",
            "  ✗ message\n",
            "  ✗ framework\n",
            "  ✗ documents\n",
            "  ✗ arrangements\n",
            "  ✗ t-sql\n",
            "  ✗ jwt\n",
            "  ✗ management\n",
            "  ✗ operators\n",
            "  ✗ manuals\n",
            "  ✗ json\n",
            "  ✗ duties\n",
            "  ✗ rules\n",
            "  ✗ safety\n",
            "  ✗ degree\n",
            "  ✗ problems\n",
            "  ✗ programmers\n",
            "  ✗ activities\n",
            "  ✗ devops\n",
            "  ✗ oauth2\n",
            "  ✗ server\n",
            "  ✗ issues\n",
            "  ✗ api\n",
            "  ✗ level\n",
            "  ✗ definition\n",
            "  ✗ minimum\n",
            "  ✗ diagram\n",
            "  ✗ re\n",
            "  ✗ visual studio\n",
            "  ✗ document\n",
            "  ✗ player\n",
            "  ✗ programs\n",
            "  ✗ html5\n",
            "  ✗ status\n",
            "  ✗ variety\n",
            "  ✗ testing\n",
            "  ✗ error\n",
            "  ✗ rest\n",
            "  ✗ modifies\n",
            "  ✗ errors\n",
            "  ✗ maintenance\n",
            "  ✗ designs\n",
            "  ✗ procedure\n",
            "  ✗ impact\n",
            "  ✗ soap\n",
            "  ✗ ef\n",
            "--------------------------------------------------\n",
            "\n",
            "Rank 2: saisurya_resume (2) (3) (1).docx\n",
            "Similarity Score: 13.1%\n",
            "Skill Match Ratio: 21.48%\n",
            "Fit for Position: No\n",
            "\n",
            "Matching Skills:\n",
            "  ✓ design\n",
            "  ✓ css\n",
            "  ✓ standards\n",
            "  ✓ concepts\n",
            "  ✓ projects\n",
            "  ✓ software\n",
            "  ✓ web\n",
            "  ✓ programming\n",
            "  ✓ sql\n",
            "  ✓ knowledge\n",
            "  ✓ development\n",
            "  ✓ c\n",
            "  ✓ team\n",
            "  ✓ tools\n",
            "  ✓ role\n",
            "  ✓ techniques\n",
            "  ✓ communication\n",
            "  ✓ experience\n",
            "  ✓ data\n",
            "  ✓ ability\n",
            "  ✓ database\n",
            "  ✓ environment\n",
            "  ✓ skills\n",
            "  ✓ system\n",
            "  ✓ bachelor\n",
            "  ✓ documentation\n",
            "  ✓ detail\n",
            "  ✓ problem\n",
            "  ✓ technologies\n",
            "  ✓ core\n",
            "  ✓ efficiency\n",
            "  ✓ program\n",
            "\n",
            "Missing Skills:\n",
            "  ✗ systems\n",
            "  ✗ work\n",
            "  ✗ maintains\n",
            "  ✗ responsibility\n",
            "  ✗ engineers\n",
            "  ✗ variables\n",
            "  ✗ reactjs\n",
            "  ✗ troubleshoots\n",
            "  ✗ code\n",
            "  ✗ unit\n",
            "  ✗ health\n",
            "  ✗ http\n",
            "  ✗ business\n",
            "  ✗ reports\n",
            "  ✗ portals\n",
            "  ✗ versions\n",
            "  ✗ acentra\n",
            "  ✗ lifecycle\n",
            "  ✗ adapts\n",
            "  ✗ needs\n",
            "  ✗ concerns\n",
            "  ✗ instructions\n",
            "  ✗ usability\n",
            "  ✗ volume\n",
            "  ✗ healthcare\n",
            "  ✗ specifications\n",
            "  ✗ -\n",
            "  ✗ operation\n",
            "  ✗ standardization\n",
            "  ✗ developer\n",
            "  ✗ supervision\n",
            "  ✗ test\n",
            "  ✗ solutions\n",
            "  ✗ coordination\n",
            "  ✗ equipment\n",
            "  ✗ researches\n",
            "  ✗ functions\n",
            "  ✗ asp.net\n",
            "  ✗ logic\n",
            "  ✗ codes\n",
            "  ✗ applications\n",
            "  ✗ entity\n",
            "  ✗ bugs\n",
            "  ✗ studio\n",
            "  ✗ requirements\n",
            "  ✗ capabilities\n",
            "  ✗ user\n",
            "  ✗ use\n",
            "  ✗ .net\n",
            "  ✗ organization\n",
            "  ✗ years\n",
            "  ✗ azure\n",
            "  ✗ support\n",
            "  ✗ t\n",
            "  ✗ changes\n",
            "  ✗ correspondence\n",
            "  ✗ suppliers\n",
            "  ✗ mvc.net\n",
            "  ✗ form\n",
            "  ✗ schedule\n",
            "  ✗ situations\n",
            "  ✗ value\n",
            "  ✗ computer\n",
            "  ✗ title\n",
            "  ✗ phase\n",
            "  ✗ aptitude\n",
            "  ✗ corrections\n",
            "  ✗ jquery\n",
            "  ✗ designers\n",
            "  ✗ tests\n",
            "  ✗ tfs\n",
            "  ✗ typescript\n",
            "  ✗ message\n",
            "  ✗ framework\n",
            "  ✗ documents\n",
            "  ✗ arrangements\n",
            "  ✗ t-sql\n",
            "  ✗ jwt\n",
            "  ✗ management\n",
            "  ✗ operators\n",
            "  ✗ manuals\n",
            "  ✗ json\n",
            "  ✗ duties\n",
            "  ✗ rules\n",
            "  ✗ safety\n",
            "  ✗ degree\n",
            "  ✗ problems\n",
            "  ✗ programmers\n",
            "  ✗ activities\n",
            "  ✗ devops\n",
            "  ✗ oauth2\n",
            "  ✗ server\n",
            "  ✗ issues\n",
            "  ✗ api\n",
            "  ✗ level\n",
            "  ✗ definition\n",
            "  ✗ minimum\n",
            "  ✗ diagram\n",
            "  ✗ re\n",
            "  ✗ visual studio\n",
            "  ✗ document\n",
            "  ✗ player\n",
            "  ✗ programs\n",
            "  ✗ html5\n",
            "  ✗ status\n",
            "  ✗ variety\n",
            "  ✗ testing\n",
            "  ✗ error\n",
            "  ✗ rest\n",
            "  ✗ modifies\n",
            "  ✗ errors\n",
            "  ✗ maintenance\n",
            "  ✗ designs\n",
            "  ✗ procedure\n",
            "  ✗ impact\n",
            "  ✗ soap\n",
            "  ✗ ef\n",
            "--------------------------------------------------\n",
            "\n",
            "Detailed results saved to resume_ranking_20250204_004935.json\n",
            "\n",
            "=== Best Matching Resume ===\n",
            "Filename: saisurya.docx\n",
            "Similarity Score: 13.11%\n",
            "Skill Match Ratio: 21.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-7n3u_AUbr-J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}